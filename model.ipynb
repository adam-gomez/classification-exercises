{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from env import user, password, host\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-98510dfdf431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_titanic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df = prep_titanic()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df['sex']).drop(columns=['male'])\n",
    "df = pd.concat([df, dummy_df], axis=1).drop(columns=['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_class'] = df['pclass'].apply(lambda p: 1 if p == 1 else 0)\n",
    "df['second_class'] = df['pclass'].apply(lambda p: 1 if p == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['first_class', 'second_class','age','fare']]\n",
    "y = df[['survived']]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train, validate, test sets\n",
    "X_train_validate, X_test  = train_test_split(X, test_size = .20, random_state = 123)\n",
    "y_train_validate, y_test = train_test_split(y, test_size = .20, random_state = 123, stratify = y.survived)\n",
    "\n",
    "X_train, X_validate  = train_test_split(X_train_validate, test_size = .30, random_state = 123)\n",
    "y_train, y_validate = train_test_split(y_train_validate, test_size = .30, random_state = 123, stratify = y_train_validate.survived)\n",
    "print(\"train: \", X_train.shape, \", validate: \", X_validate.shape, \", test: \", X_test.shape)\n",
    "print(\"train: \", y_train.shape, \", validate: \", y_validate.shape, \", test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing age values\n",
    "print(X_train.age.mean()) # We will use the train set mean age for our imputed mean \n",
    "print(X_validate.age.mean())\n",
    "print(X_test.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0)\n",
    "X_train.iloc[:,:] = mean_imputer.fit_transform(X_train)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate['age'].fillna(inplace=True, value=X_train['age'].mean())\n",
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['age'].fillna(inplace=True, value=X_train['age'].mean())\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasoning for using the train set mean age in all sets is that our model is built on the inherent assumption that our average age is 29.17. When we receive data we have never seen before (which is what the validate and test set represent) we would have no way of knowing what the mean age for future data would be. We can only use what we know for sure, which is our train data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Start by defining your baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of passengers on the titanic appeared to have died. We will use a model of always predicting \"not survived\" as our baseline to compare future models to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If that baseline model was applied to the train data\n",
    "baseline_accuracy_train = round(1 - y_train.survived.mean(),2)\n",
    "baseline_accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model has a 62% accuracy on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Create another model that includes age in addition to fare and pclass. Does this model perform better than your baseline?\n",
    "\n",
    "We previously optimized our data to create the model this question is asking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(C = 1)\n",
    "model1.fit(X_train, y_train)\n",
    "print('Coefficient: ', model1.coef_)\n",
    "print('Intercept: ', model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate whether or not a passenger would survive, using the training data\n",
    "y_pred = model1.predict(X_train)\n",
    "#Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = model1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(model1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Model is identical to baseline. It predicted that each passenger would die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE MODEL ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_validate)\n",
    "print(\"Model 4\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(model1.score(X_validate, y_validate)))\n",
    "\n",
    "print(confusion_matrix(y_validate, y_pred1))\n",
    "\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating our X_train DataFrame with 'female' added\n",
    "df = prep_titanic()\n",
    "dummy_df = pd.get_dummies(df['sex']).drop(columns=['male'])\n",
    "df = pd.concat([df, dummy_df], axis=1).drop(columns=['sex'])\n",
    "df['first_class'] = df['pclass'].apply(lambda p: 1 if p == 1 else 0)\n",
    "df['second_class'] = df['pclass'].apply(lambda p: 1 if p == 2 else 0)\n",
    "X = df[['first_class', 'second_class','age','fare', 'female']]\n",
    "y = df[['survived']]\n",
    "X_train_validate, X_test  = train_test_split(X, test_size = .20, random_state = 123)\n",
    "y_train_validate, y_test = train_test_split(y, test_size = .20, random_state = 123, stratify = y.survived)\n",
    "X_train, X_validate  = train_test_split(X_train_validate, test_size = .30, random_state = 123)\n",
    "y_train, y_validate = train_test_split(y_train_validate, test_size = .30, random_state = 123, stratify = y_train_validate.survived)\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0)\n",
    "X_train.iloc[:,:] = mean_imputer.fit_transform(X_train)\n",
    "X_validate['age'].fillna(inplace=True, value=X_train['age'].mean())\n",
    "X_test['age'].fillna(inplace=True, value=X_train['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression(C = 1)\n",
    "model2.fit(X_train, y_train)\n",
    "print('Coefficient: ', model2.coef_)\n",
    "print('Intercept: ', model2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate whether or not a passenger would survive, using the training data\n",
    "y_pred = model2.predict(X_train)\n",
    "#Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = model2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(model2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after adding in sex, our Model is identical to baseline. It predicted that each passenger would die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_validate)\n",
    "print(\"Model 2\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(model2.score(X_validate, y_validate)))\n",
    "\n",
    "print(confusion_matrix(y_validate, y_pred2))\n",
    "\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Try out other combinations of features and models.\n",
    "\n",
    "We will run a model that only has class, sex, and age as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating our X_train DataFrame with only class, sex, and age as features\n",
    "df = prep_titanic()\n",
    "dummy_df = pd.get_dummies(df['sex']).drop(columns=['male'])\n",
    "df = pd.concat([df, dummy_df], axis=1).drop(columns=['sex'])\n",
    "df['first_class'] = df['pclass'].apply(lambda p: 1 if p == 1 else 0)\n",
    "df['second_class'] = df['pclass'].apply(lambda p: 1 if p == 2 else 0)\n",
    "X = df[['first_class', 'second_class','age', 'female']]\n",
    "y = df[['survived']]\n",
    "X_train_validate, X_test  = train_test_split(X, test_size = .20, random_state = 123)\n",
    "y_train_validate, y_test = train_test_split(y, test_size = .20, random_state = 123, stratify = y.survived)\n",
    "X_train, X_validate  = train_test_split(X_train_validate, test_size = .30, random_state = 123)\n",
    "y_train, y_validate = train_test_split(y_train_validate, test_size = .30, random_state = 123, stratify = y_train_validate.survived)\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0)\n",
    "X_train.iloc[:,:] = mean_imputer.fit_transform(X_train)\n",
    "X_validate['age'].fillna(inplace=True, value=X_train['age'].mean())\n",
    "X_test['age'].fillna(inplace=True, value=X_train['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(C = 1)\n",
    "model3.fit(X_train, y_train)\n",
    "print('Coefficient: ', model3.coef_)\n",
    "print('Intercept: ', model3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate whether or not a passenger would survive, using the training data\n",
    "y_pred = model3.predict(X_train)\n",
    "#Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = model3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(model3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(X_validate)\n",
    "print(\"Model 4\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(model3.score(X_validate, y_validate)))\n",
    "\n",
    "print(confusion_matrix(y_validate, y_pred3))\n",
    "\n",
    "print(classification_report(y_validate, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A ONE FEATURE MODEL (SEX ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating our X_train DataFrame with only class, sex, and age as features\n",
    "df = prep_titanic()\n",
    "dummy_df = pd.get_dummies(df['sex']).drop(columns=['male'])\n",
    "df = pd.concat([df, dummy_df], axis=1).drop(columns=['sex'])\n",
    "df['first_class'] = df['pclass'].apply(lambda p: 1 if p == 1 else 0)\n",
    "df['second_class'] = df['pclass'].apply(lambda p: 1 if p == 2 else 0)\n",
    "X = df[['female']]\n",
    "y = df[['survived']]\n",
    "X_train_validate, X_test  = train_test_split(X, test_size = .20, random_state = 123)\n",
    "y_train_validate, y_test = train_test_split(y, test_size = .20, random_state = 123, stratify = y.survived)\n",
    "X_train, X_validate  = train_test_split(X_train_validate, test_size = .30, random_state = 123)\n",
    "y_train, y_validate = train_test_split(y_train_validate, test_size = .30, random_state = 123, stratify = y_train_validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LogisticRegression()\n",
    "model4.fit(X_train, y_train)\n",
    "print('Coefficient: ', model4.coef_)\n",
    "print('Intercept: ', model4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate whether or not a passenger would survive, using the training data\n",
    "y_pred = model4.predict(X_train)\n",
    "#Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = model4.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(model4.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsure why these model coefficients are being calculated so low. It is clear that sex has an incredible influence on survival rate, yet the model is giving a tiny coefficent. Something is not being calculated correctly in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Use your best 3 models to predict and evaluate on your validate sample\n",
    "\n",
    "Considering that no model exceeded baseline, we could use any model. \n",
    "\n",
    "For the sake of the kernel flow, this question was retroactively added to earlier cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(X_validate)\n",
    "print(\"Model 4\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(model4.score(X_validate, y_validate)))\n",
    "\n",
    "print(confusion_matrix(y_validate, y_pred4))\n",
    "\n",
    "print(classification_report(y_validate, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(X_test)\n",
    "y_pred4_proba = model4.predict_proba(X_test)\n",
    "\n",
    "print(\"Model 4\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(model4.score(X_test, y_test)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred4))\n",
    "\n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All performance measures are identical to validate, train, and baseline. No features were identified to have any impact on survival. This is obviously wrong, but I do not know why these models are not producing large enough coefficients. \n",
    "\n",
    "I will confer with the Data Science cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
