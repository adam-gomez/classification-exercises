{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Exercises\n",
    "\n",
    "This .inpyb file will eventually be joined to model.ipynb per the curriculum instructions, but because model.ipynb needs to be rebuilt from the bottom up, I will store the solutions here for now, and copy to model.ipynb once that file is running as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "from env import user, password, host\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_titanic()\n",
    "dummy_df = pd.get_dummies(df['sex']).drop(columns=['male'])\n",
    "df = pd.concat([df, dummy_df], axis=1).drop(columns=['sex'])\n",
    "X = df[['pclass', 'age', 'sibsp', 'parch', 'fare', 'alone', 'Q', 'S', 'female']]\n",
    "X['age'].fillna(inplace=True, value=X['age'].mean())\n",
    "y = df[['survived']]\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123, stratify=y.survived)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123, stratify=y_train_validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08958006 0.2462471  0.05101585 0.03355855 0.28881728 0.0234286\n",
      " 0.01138673 0.02310322 0.23286261]\n",
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'alone', 'Q', 'S', 'female'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(random_state = 123, min_samples_leaf = 1, max_depth = 20)\n",
    "rf1.fit(X_train, y_train)\n",
    "print(rf1.feature_importances_)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = rf1.predict(X_train)\n",
    "y_pred1_proba = rf1.predict_proba(X_train)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[305   2]\n",
      " [  4 186]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       307\n",
      "           1       0.99      0.98      0.98       190\n",
      "\n",
      "    accuracy                           0.99       497\n",
      "   macro avg       0.99      0.99      0.99       497\n",
      "weighted avg       0.99      0.99      0.99       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive is defined as dying; Negative is defined as surviving\n",
      "True positives: 305\n",
      "False negatives: 4\n",
      "False positives: 2\n",
      "True negatives: 186\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix1 = confusion_matrix(y_train, y_pred1)\n",
    "\n",
    "print(f'Positive is defined as dying; Negative is defined as surviving')\n",
    "true_positive_count = confusion_matrix1[0][0]\n",
    "print(f'True positives: {true_positive_count}')\n",
    "false_negative_count = confusion_matrix1[1][0]\n",
    "print(f'False negatives: {false_negative_count}')\n",
    "false_positive_count = confusion_matrix1[0][1]\n",
    "print(f'False positives: {false_positive_count}')\n",
    "true_negative_count = confusion_matrix1[1][1]\n",
    "print(f'True negatives: {true_negative_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14754544 0.06312049 0.04542362 0.02189998 0.2011621  0.05112113\n",
      " 0.00816355 0.00850593 0.45305775]\n",
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'alone', 'Q', 'S', 'female'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(random_state = 123, min_samples_leaf = 5, max_depth = 3)\n",
    "rf2.fit(X_train, y_train)\n",
    "print(rf2.feature_importances_)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = rf2.predict(X_train)\n",
    "y_pred2_proba = rf2.predict_proba(X_train)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[288  19]\n",
      " [ 66 124]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.84      0.80      0.81       497\n",
      "weighted avg       0.83      0.83      0.82       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: min_samples_leaf = 1, max_depth = 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       307\n",
      "           1       0.99      0.98      0.98       190\n",
      "\n",
      "    accuracy                           0.99       497\n",
      "   macro avg       0.99      0.99      0.99       497\n",
      "weighted avg       0.99      0.99      0.99       497\n",
      "\n",
      "Model 2: min_samples_leaf = 5, max_depth = 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.84      0.80      0.81       497\n",
      "weighted avg       0.83      0.83      0.82       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1: min_samples_leaf = 1, max_depth = 20')\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print('Model 2: min_samples_leaf = 5, max_depth = 3')\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 Performs better on every metric possible\n",
    "# It is very likely that model 1 is overfitting the training data and would generalize very poorly to a validate or test set\n",
    "# This is because the depth is so high and the minimum samples leaf setting is so low that each leaf in model 1 contains a very small number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      fare  female\n",
       "583  36.000000   40.1250       0\n",
       "337  41.000000  134.5000       1\n",
       "50    7.000000   39.6875       0\n",
       "218  32.000000   76.2917       1\n",
       "31   29.642093  146.5208       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age, Fare, and Female have the greatest weight in both models generated so far, so I will create a third model only using those features\n",
    "X_train.drop(columns=['pclass', 'sibsp', 'parch', 'alone', 'Q', 'S'], inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17394507 0.34500947 0.48104546]\n",
      "Index(['age', 'fare', 'female'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(random_state = 123, min_samples_leaf = 5, max_depth = 3)\n",
    "rf3.fit(X_train, y_train)\n",
    "print(rf3.feature_importances_)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = rf3.predict(X_train)\n",
    "y_pred3_proba = rf3.predict_proba(X_train)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[278  29]\n",
      " [ 71 119]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       307\n",
      "           1       0.80      0.63      0.70       190\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.80      0.77      0.78       497\n",
      "weighted avg       0.80      0.80      0.79       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.84\n",
      "Accuracy of Decision Tree classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Now we will compare the performance of all three models on validate\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(rf1.score(X_validate, y_validate)))\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(rf2.score(X_validate, y_validate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age     fare  female\n",
       "610  39.000000  31.2750       1\n",
       "424  18.000000  20.2125       0\n",
       "568  29.642093   7.2292       0\n",
       "701  35.000000  26.2875       0\n",
       "101  29.642093   7.8958       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.drop(columns=['pclass', 'sibsp', 'parch', 'alone', 'Q', 'S'], inplace=True)\n",
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(rf3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, Model1 performed the best by a large margin despite the risk of overfitting. \n",
    "\n",
    "#### Recommendation: pass Model 1 to the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
